{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wcAZLL7sNFIA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "# import PILs\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "#from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import applications\n",
    "import keras.optimizers\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, plot_roc_curve, recall_score, mean_squared_error\n",
    "# from pycaret.regression import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8HJaQAUoiLDp",
    "outputId": "f9215923-292d-4ba9-8a99-55649efee02b"
   },
   "outputs": [],
   "source": [
    "#4\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5g9EUBnSCTDc"
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(path, batch_size):\n",
    "\n",
    "    batch = batch_size\n",
    "    img_height = 200\n",
    "    img_width = 200\n",
    "\n",
    "    dataset_url = path\n",
    "\n",
    "    data_dir = pathlib.Path(dataset_url)\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      validation_split=0.80,          # try out 20% as training data\n",
    "      subset=\"training\",\n",
    "      image_size=(img_height, img_width),\n",
    "      batch_size=batch,\n",
    "      seed = 155)\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "      data_dir,\n",
    "      validation_split=0.05,          #try out 5% as validation data\n",
    "      subset=\"validation\",\n",
    "      image_size=(img_height, img_width),\n",
    "      batch_size=batch, seed = 155)\n",
    "\n",
    "    test_ds = train_ds.take(300) \n",
    "    train_ds = train_ds.skip(300)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kC9qlRWBDKtI",
    "outputId": "0979536e-aec2-40b3-af38-0444832cfb3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192312 files belonging to 2 classes.\n",
      "Using 38463 files for training.\n",
      "Found 192312 files belonging to 2 classes.\n",
      "Using 9615 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = train_val_test_split(\"coad_msi_mss\",32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "G1IV73rASVs7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def densenet_model():\n",
    "    densenet = applications.densenet.DenseNet201(\n",
    "        weights= 'imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(200,200,3))\n",
    "\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        densenet,\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.4),\n",
    "        Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        Flatten(),\n",
    "        Dropout(0.4),\n",
    "        BatchNormalization(),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VAS0hLJWKjfD"
   },
   "outputs": [],
   "source": [
    "def model_running(epochs):\n",
    "    model = densenet_model()\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.01, name=\"SGD\")\n",
    "    model.compile(optimizer=opt, loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    learn_control = ReduceLROnPlateau(monitor='loss', patience=5, verbose=1, factor=0.2, min_lr=1e-7)\n",
    "    filepath=\"best_model.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    history = model.fit(train_ds, use_multiprocessing = True, workers = 32, epochs=epochs, validation_data=val_ds,\n",
    "                        callbacks = [learn_control,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HlmAbyFqLMXY",
    "outputId": "91470e2f-b7d4-480f-964e-c73c5fa83d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 1s 0us/step\n",
      "74850304/74836368 [==============================] - 1s 0us/step\n",
      "Epoch 1/10\n",
      "902/902 [==============================] - 1026s 1s/step - loss: 0.6290 - accuracy: 0.6651 - val_loss: 0.6125 - val_accuracy: 0.6690\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66895, saving model to best_model.hdf5\n",
      "Epoch 2/10\n",
      "902/902 [==============================] - 955s 1s/step - loss: 0.4468 - accuracy: 0.7979 - val_loss: 0.5021 - val_accuracy: 0.7547\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66895 to 0.75465, saving model to best_model.hdf5\n",
      "Epoch 3/10\n",
      "902/902 [==============================] - 949s 1s/step - loss: 0.3415 - accuracy: 0.8534 - val_loss: 0.4983 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75465 to 0.77015, saving model to best_model.hdf5\n",
      "Epoch 4/10\n",
      "902/902 [==============================] - 949s 1s/step - loss: 0.2597 - accuracy: 0.8966 - val_loss: 0.5485 - val_accuracy: 0.7657\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77015\n",
      "Epoch 5/10\n",
      "902/902 [==============================] - 948s 1s/step - loss: 0.2037 - accuracy: 0.9220 - val_loss: 0.8711 - val_accuracy: 0.7216\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77015\n",
      "Epoch 6/10\n",
      "902/902 [==============================] - 949s 1s/step - loss: 0.1762 - accuracy: 0.9338 - val_loss: 0.7210 - val_accuracy: 0.7490\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77015\n",
      "Epoch 7/10\n",
      "902/902 [==============================] - 949s 1s/step - loss: 0.1352 - accuracy: 0.9497 - val_loss: 0.8377 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77015\n",
      "Epoch 8/10\n",
      "902/902 [==============================] - 951s 1s/step - loss: 0.1110 - accuracy: 0.9608 - val_loss: 0.8233 - val_accuracy: 0.7551\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77015\n",
      "Epoch 9/10\n",
      "902/902 [==============================] - 949s 1s/step - loss: 0.1158 - accuracy: 0.9580 - val_loss: 0.6161 - val_accuracy: 0.7810\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.77015 to 0.78097, saving model to best_model.hdf5\n",
      "Epoch 10/10\n",
      "902/902 [==============================] - 948s 1s/step - loss: 0.0872 - accuracy: 0.9682 - val_loss: 0.4306 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.78097 to 0.84701, saving model to best_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "model_running(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gR0rFXCbU1IU"
   },
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"best_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XNxwSRPHsjz1"
   },
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    y_pred = []  # store predicted labels\n",
    "    y_true = []  # store true labels\n",
    "\n",
    "  # iterate over the dataset\n",
    "    for image_batch, label_batch in test_ds:   # use dataset.unbatch() with repeat\n",
    "        # append true labels\n",
    "        y_true.append(label_batch)\n",
    "        # compute predictions\n",
    "        preds = best_model.predict(image_batch)\n",
    "        # append predicted labels\n",
    "        y_pred.append(np.argmax(preds, axis = - 1))\n",
    "\n",
    "    # convert the true and predicted labels into tensors\n",
    "    correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "    predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
    "  \n",
    "    print(pd.crosstab(correct_labels, predicted_labels,rownames=[\"Actual\"], colnames=[\"Predict\"], margins= True))\n",
    "    print(confusion_matrix(predicted_labels, correct_labels))\n",
    "\n",
    "    return correct_labels, predicted_labels\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3FL6rYLO9Aa",
    "outputId": "531439da-7951-4342-859c-941f838123b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict     0     1   All\n",
      "Actual                   \n",
      "0        2792   968  3760\n",
      "1         398  5442  5840\n",
      "All      3190  6410  9600\n",
      "[[2792  398]\n",
      " [ 968 5442]]\n"
     ]
    }
   ],
   "source": [
    "correct_labels, predicted_labels = evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qb5E9Td8Qw6B",
    "outputId": "c7c83906-bd24-4bcf-e4b8-ad2d9fc0c76a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8577083333333333\n",
      "f1-score 0.8884897959183672\n",
      "precision 0.8489859594383775\n",
      "recall 0.9318493150684931\n",
      "RMSE 0.3772156765918759\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    f1 = f1_score(true, predicted)\n",
    "    precision = precision_score(true, predicted)\n",
    "    recall = recall_score(true, predicted)\n",
    "    RMSE = mean_squared_error(true, predicted, squared=False)\n",
    "\n",
    "    print(\"accuracy\",accuracy)\n",
    "    print(\"f1-score\", f1)\n",
    "    print(\"precision\", precision)\n",
    "    print(\"recall\", recall)\n",
    "    print(\"RMSE\", RMSE)\n",
    "\n",
    "    return accuracy, f1, precision, recall, RMSE\n",
    "\n",
    "accuracy, f1, precision, recall, RMSE = compute_metrics(correct_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymx24M2FXFbp"
   },
   "outputs": [],
   "source": [
    "def model_store(accuracy):\n",
    "    file = open('model_database.csv')\n",
    "    csvreader = csv.reader(file)\n",
    "    num_rows=len(list(csvreader))\n",
    "    if num_rows == 0 or num_rows == 1:\n",
    "        with open('model_database.csv', 'w', encoding='UTF8', newline='') as csvfile:\n",
    "            fieldnames = ['model', 'accuracy', 'f1', 'precision', 'recall', 'RMSE']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerow({\"model\": \"best_model\", \"accuracy\":accuracy, 'f1':f1, \n",
    "                           'precision':precision, 'recall':recall, 'RMSE':RMSE})\n",
    "        print(\"model added to database\")\n",
    "    elif num_rows >1:\n",
    "        file = open('model_database.csv')\n",
    "        csvreader = csv.reader(file)\n",
    "        next(csvreader)\n",
    "        for row in csvreader:\n",
    "            if float(row[1]) < accuracy:\n",
    "                with open('model_database.csv', 'w') as w_file:\n",
    "                    fieldnames = ['model', 'accuracy', 'f1', 'precision', 'recall', 'RMSE']\n",
    "                    writer = csv.DictWriter(w_file, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    writer.writerow({\"model\": \"updated_model\", \"accuracy\":accuracy , 'f1':f1, \n",
    "                                   'precision':precision, 'recall':recall, 'RMSE':RMSE})\n",
    "                print(\"database updated with new model\")\n",
    "            else:\n",
    "                print(\"database not updated\")\n",
    "    file.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9neQ4Z6geOw",
    "outputId": "e99937f3-1cc1-463a-94df-ccb03509b3a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database updated with new model\n"
     ]
    }
   ],
   "source": [
    "model_store(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1G76ZuhJoKDA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3164_first_draft_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
